---
title: "dissertation code"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE}
library(tidyverse)
library(ABSEIR)
library(splm)
library(openxlsx)
library(optparse)
library(reshape2)
library(lubridate)
library(splines)
library(zoo)
library(imputeTS)
```

```{r}
states <- read.csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/rolling-averages/us-states.csv", header = TRUE, sep = ",")

us <- read.csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/rolling-averages/us.csv", header = TRUE, sep = ",")

vaccinations <- read.csv("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/us_state_vaccinations.csv", header = TRUE, sep = ",")


interventions <- read.csv("https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/United%20States/OxCGRT_USA_latest.csv", header = TRUE, 
                           sep = ",")

#interventions <- interventions %>%
 # filter(CountryCode == "USA")

census_data <- read.xlsx("https://www2.census.gov/programs-surveys/popest/tables/2010-2019/state/totals/nst-est2019-01.xlsx", startRow = 10, colNames = FALSE)
```

```{r}

total_cases_by_state <- states %>%
  group_by(state) %>% 
  summarise(total_cases = sum(cases)) %>%
  filter(!state %in% c('Alaska', "American Samoa", "District of Columbia", "Guam", 'Hawaii', "Northern Mariana Islands", "Puerto Rico", "Virgin Islands"))

# reordering and manipulating current dataframe so that states appear both alphabetically and as column headers according to date...data corresponds only to new cases per day

# also replace NA values with zeroes

states <- states[order(states$state),]
states <- select(states, -c(2,5:9))


#mobility <- read.csv("Global_Mobility_Report.csv", header = TRUE, 
          #                 sep = ",")
 

# removing alaska, district of columbia, hawaii and puerto rico (along with other irrelevant rows at bottom of original spreadsheet) since not in usaww spatial matrix

rows_to_remove<-c("2","9","12", "52", "53", "54", "55","56", "57") 
census_data <- census_data[!(row.names(census_data) %in% rows_to_remove),]

N <- census_data$`X13`  # manipulate census dataset so that it is similar to usaww matrix...X13 corresponds to 2019 data

total_cases_by_state$pop <- N
total_cases_by_state$total_cases_per_100k <- total_cases_by_state$total_cases/total_cases_by_state$pop * 1e5


# also remove rows in states dataset which are not present in usaww matrix

states <- states %>%
  filter(!state %in% c('Alaska', "American Samoa", "District of Columbia", "Guam", 'Hawaii', "Northern Mariana Islands", "Puerto Rico", "Virgin Islands"))

vaccinations <- vaccinations %>% 
  filter(!location %in% c('Alaska', "American Samoa", "Bureau of Prisons", "Dept of Defense","District of Columbia", "Federated States of Micronesia", "Indian Health Svc", "Long Term Care","Marshall Islands","Guam", 'Hawaii', "Northern Mariana Islands", "Puerto Rico", "Republic of Palau", "United States","Veterans Health" , "Virgin Islands"))

vaccinations <- vaccinations %>%
    group_by(location) %>%
    mutate(fully_vaxxed_per_hundred_corrected = people_fully_vaccinated_per_hundred) %>%
    fill(fully_vaxxed_per_hundred_corrected, .direction = "downup") %>%   # filling in NAs with closest value
    ungroup()


states_new_cases <- spread(states, state, cases)
states_new_cases <- states_new_cases %>%
  mutate_all(~replace(., is.na(.), 0))

fully_vaxxed <- vaccinations %>%
  select(date, location, fully_vaxxed_per_hundred_corrected) 
fully_vaxxed <- spread(fully_vaxxed, location, fully_vaxxed_per_hundred_corrected)
# n_distinct(states$state) ..... checking that there are 48 unique state entries
```

```{r}

# R crashes when running code with all 48 spatial locations so consider subsetting regions into NE, MW, S and W to reduce dimensions of matrices
data("usaww")
spatial_data <- ( usaww > 0)*1


#spatial_data[spatial_data > 0] <- 1

```


```{r}

# adding weeks from date of first recorded cases

states_new_cases <- states_new_cases %>%
  mutate(weeks = as.numeric(floor(difftime(states_new_cases$date, as.Date("2020-01-21"), units="weeks")+1)))

weeks <- unique(states_new_cases$weeks)


first_wave = as.Date("2020-09-30", "%Y-%m-%d")

second_wave_start = as.Date("2020-03-30", "%Y-%m-%d")
second_wave_end = as.Date("2021-10-31", "%Y-%m-%d")

firstandsecond_wave = as.Date("2021-06-31", "%Y-%m-%d")

third_wave = as.Date("2021-08-31", "%Y-%m-%d")

#states_new_cases %>%
  #filter(date <= "2020-09-30")
  #filter(date <= "2021-03-31")

#second_wave <- states_new_cases %>%
  #filter(date >= "2021-03-31" & date <= "2021-10-31" )

#firstandsecond_wave <- states_new_cases %>%
  #filter(date <= "2021-06-31" )


#third_wave <- states_new_cases %>%
 # filter(date >= "2021-08-31")


```


```{r}
confirmed_cases <- states_new_cases[-c(50)] %>% select(., -c('date')) # first wave for shortened epidemic timeline
epidemic.start = min(which(apply(confirmed_cases, 1, max) > 0)) # starts in week 1 or epoch week 3
confirmed_cases = confirmed_cases[(epidemic.start-1):nrow(confirmed_cases),]
#confirmed_cases <- confirmed_cases %>%
  #apply(., 2,cumsum)

colnames(spatial_data) <- gsub('[[:punct:] ]+','',colnames(spatial_data))
rownames(spatial_data) <- gsub('[[:punct:] ]+','',rownames(spatial_data))

colnames(confirmed_cases) <- confirmed_cases %>%
  colnames(.) %>% 
  toupper() %>%
  gsub(' ', '',.)

colnames(fully_vaxxed) <- fully_vaxxed %>%
  colnames(.) %>% 
  toupper() %>%
  gsub(' ', '',.)

census_data$X1 <- census_data$X1 %>% 
  toupper() %>% 
  sub("\\.", "",.) %>% 
  gsub(' ', '',.)

# in spatial data matrix tennessee is spelled as tennesse so for uniformity we change to match the correct spelling

colnames(spatial_data)[which(colnames(spatial_data) == 'TENNESSE')] <- 'TENNESSEE'
rownames(spatial_data)[which(rownames(spatial_data) == 'TENNESSE')] <- 'TENNESSEE'

```

```{r}

# checking that names in spatial matrix and population data match 

#test_census_names = census_data$`X1`[-c(21:51)] 
if (!all(census_data$`X1` == colnames(spatial_data))){
  stop("Error, make sure spatial unit ordering is consistent.")
}

```

```{r}
# S = South .....as defined by United States Census Bureau

#W <-c("NEWJERSEY", "PENNSYLVANIA", "OHIO") 
sub <-c("ALABAMA", "FLORIDA", "GEORGIA") 

# get confirmed cases, N and spatial data for this region

confirmed_sub <- confirmed_cases[,sub] 
epidemic.start_sub = min(which(apply(confirmed_sub, 1, max) > 0)) # starts in week 1 or epoch week 3
confirmed_sub = confirmed_sub[(epidemic.start_sub-1):nrow(confirmed_sub),]

confirmed_sub_with_date <- confirmed_sub %>%
  add_column(seq.Date(from = as.Date(states_new_cases$date[epidemic.start_sub-1], "%Y-%m-%d"), length.out = dim(confirmed_sub)[1], by="day"))

N <- census_data[grepl(paste(sub, collapse="|"), census_data$X1),] %>% 
  subset(., select = c("X13"))

spatial_sub <- spatial_data[rownames(spatial_data)%in%sub,colnames(spatial_data)%in%sub]

test_vaxx <- fully_vaxxed[,sub]

confirmed_sub[confirmed_sub == 0] <- NA
confirmed_sub[confirmed_sub < 0] <- NA
confirmed_sub<-na.approx(confirmed_sub) %>% ceiling() # fills in zeroes and negative values with average of two closest values
confirmed_sub <- replace(confirmed_sub, is.na(confirmed_sub), 0)  
```

```{r}
first_wave_timepoints <- confirmed_sub_with_date[-1,] %>%
  filter(`seq.Date(...)` <= "2020-09-30") %>% 
  nrow()

firstandsecond_wave_timepoints <- confirmed_sub_with_date[-1,] %>%
  filter(`seq.Date(...)` <= "2021-06-30") %>% 
  nrow()


first_wave_confirmed_sub <- confirmed_sub[1:first_wave_timepoints,]

firstandsecond_wave_confirmed_sub <- confirmed_sub[1:firstandsecond_wave_timepoints,]
firstandsecond_wave_confirmed_sub_with_date <- confirmed_sub_with_date[-1,] %>%
  filter(`seq.Date(...)` <= "2021-06-30")


```




```{r data, echo=TRUE, eval=TRUE}

#data_model_fl = DataModel(states$cases,
                       # type = "identity",
                       # compartment="I_star",
                       # cumulative=FALSE)

data_model_1 = DataModel(Y=apply(first_wave_confirmed_sub, 2,cumsum), 
                             type = "identity",      # Assume data is correct 
                             compartment = "I_star", # Data related to new infections
                             cumulative = TRUE       # Not reported on cumulative scale
                             )

data_model_2 = DataModel(Y=apply(firstandsecond_wave_confirmed_sub, 2,cumsum), 
                             type = "identity",      # Assume data is correct 
                             compartment = "I_star", # Data related to new infections
                             cumulative = TRUE       # Not reported on cumulative scale
                             )

# model 1 = first wave with intercepts and time basis (CAR (b) vs distance (a) vs gravity model (c))
```

```{r exposure, echo=TRUE, eval=TRUE}

sub.locations <- ncol(spatial_sub)
#sub.timepoints <- length(unique(states_new_cases$weeks))

intercepts = diag(3)[rep(1:ncol(first_wave_confirmed_sub), each = nrow(first_wave_confirmed_sub)),]
#intercepts = 1
time_basis = bs(1:nrow(first_wave_confirmed_sub), degree = 4)[rep(1:nrow(first_wave_confirmed_sub), ncol(first_wave_confirmed_sub)),] # 3 (ncol) x 214 (nrow) = 642

X = cbind(intercepts, time_basis)

#exposure_model_W = ExposureModel(timeBasis_W,
#                                nTpt = nrow(confirmed_W),
#                                nLoc = ncol(confirmed_W),
#                                betaPriorPrecision = 0.5,
 #                               betaPriorMean = c(rep(0, ncol(timeBasis_W)))) # -2.1

exposure_model_1 = ExposureModel(X, nTpt = nrow(first_wave_confirmed_sub),
                               nLoc = ncol(first_wave_confirmed_sub),
                               betaPriorPrecision = 0.5,
                               betaPriorMean = c(rep(-1, ncol(intercepts)), # -0.5
                                                 rep(-2, ncol(time_basis))))

```

```{r}
intervention_term = cumsum(firstandsecond_wave_confirmed_sub_with_date$`seq.Date(...)` > as.Date("2020-03-27", "%Y-%m-%d"))
intervention_matrix = cbind(1,intervention_term)

X_inter = matrix(rep(t(intervention_matrix),3), ncol = ncol(intervention_matrix), byrow = TRUE)

intervention_date_al = as.Date("2020-04-04", "%Y-%m-%d")
intervention_date_fl = as.Date("2020-04-03", "%Y-%m-%d")
intervention_date_ge = as.Date("2020-04-03", "%Y-%m-%d")

c_al <- cumsum(1*((firstandsecond_wave_confirmed_sub_with_date$`seq.Date(...)` >= intervention_date_al)))
c_fl <- cumsum(1*((firstandsecond_wave_confirmed_sub_with_date$`seq.Date(...)` >= intervention_date_fl)))
c_ge <- cumsum(1*((firstandsecond_wave_confirmed_sub_with_date$`seq.Date(...)` >= intervention_date_ge)))

sharedBasis <- bs(0:200, degree = 4)#[rep(1:nrow(confirmed_W), ncol(confirmed_W)),]


time_basis_al = predict(sharedBasis, c_al)
time_basis_fl = predict(sharedBasis, c_fl)
time_basis_ge = predict(sharedBasis, c_ge)


X_splines <- as.matrix(cbind(1,time_basis_al, time_basis_fl, time_basis_ge)
                       [rep(1:nrow(firstandsecond_wave_confirmed_sub), ncol(firstandsecond_wave_confirmed_sub)),])



exposure_model_inter = ExposureModel(X_splines, nTpt = nrow(firstandsecond_wave_confirmed_sub),
                               nLoc = ncol(firstandsecond_wave_confirmed_sub),
                               betaPriorPrecision = 0.5,
                               betaPriorMean = 0)

#exposure_model_w = ExposureModel(matrix(1,nrow = nrow((X))),
#                                  nTpt = nrow((confirmed_W)),
#                                  nLoc = W.locations,
#                                  betaPriorPrecision = 0.5,
#                                  betaPriorMean = 0)

#

#intervention_term_fl = cumsum(fl$date >  as.Date("2020-03-22", "%Y-%m-%d")) # date when lockdown was first imposed

#exposure_model_fl_inter = ExposureModel(cbind(1,intervention_term_fl),
#                                  nTpt = nrow(fl),
#                                  nLoc = 1,
#                                  betaPriorPrecision = 0.5,
 #                                 betaPriorMean = 0)

# nrow = 304 x ncol = 3 ...equal to 912 which is equal to the number of rows in X matrix
```


```{r}

#time_invariant_covariates <- data.frame(intercept = rep(1, ncol(test_vaxx[-1])),
#                                        fully_vaccinated = tail(test_vaxx[-1]))

#time_varying_covariates <- data.frame(sin_component = sin(weeks/52*2*pi),
 #                                     cos_component = cos(weeks/52*2*pi),
#                                      trig_interact = sin(weeks/52*2*pi)*cos(weeks/52*2*pi))
#exposure.design.matrix <- as.matrix(
 #                           cbind(
#                              time_invariant_covariates[rep(1:W.locations, each = W.timepoints),],
#                              time_varying_covariates[rep(1:W.timepoints, W.locations),]
#                            )
#)
#exposure_model <- ExposureModel(X = exposure.design.matrix,
#                                      nTpt = W.timepoints,
 #                                     nLoc = W.locations,
 #                                     betaPriorPrecision = rep(1, ncol(exposure.design.matrix)),
 #                                     betaPriorMean = rep(0, ncol(exposure.design.matrix)))
```


```{r}


I0 = (apply(first_wave_confirmed_sub[1:3,], 2, max) > 0)*2
E0 = I0
R0 = 0*I0
S0 = as.numeric(unlist(N-E0-I0-R0))

initial_values = InitialValueContainer(S0 = S0, 
                                             E0 = E0,
                                             I0 = I0,
                                             R0 = R0)
```

```{r reinfection, echo=TRUE, eval=TRUE}

reinfection_model = ReinfectionModel("SEIR") # without reinfection rate

```


```{r distance, echo=TRUE, eval=TRUE}

#distance_model = DistanceModel(list(matrix(0))) # considering as one state therefore initialising with empty matrix
#spatial_W <- ( spatial_W == 1)*1
CAR_model <- DistanceModel(list(spatial_sub), 
                                 priorAlpha = 1,
                                 priorBeta = 10
                                 )

distance_model = DistanceModel(list(
  #matrix(c(0,0,0,0,0,0,0,0,0), nrow = 3, byrow=3),  # nj and ohio
  #matrix(c(0,0,1,0,0,0,1,0,0), nrow = 3, byrow=3),  # nj and penn
  #matrix(c(0,0,0,0,0,1,0,1,0), nrow = 3, byrow=3)), # ohio and penn
  matrix(c(0,1,0,1,0,0,0,0,0), nrow = 3, byrow=3), # alabama and fl
  matrix(c(0,0,1,0,0,0,1,0,0), nrow = 3, byrow=3), # alabama and georgia
  matrix(c(0,0,0,0,0,1,0,1,0), nrow = 3, byrow=3)), # fl and georgia 
priorAlpha = 1, priorBeta = 10)

pop_matrix <- matrix(as.numeric(unlist(N)), nrow = nrow(N), ncol = nrow(N))
weighted_distance <- usaww[rownames(usaww)%in%sub,colnames(usaww)%in%sub]
gravity_model <- (pop_matrix * t(pop_matrix))/weighted_distance^2
diag(gravity_model) <- 1
max_row_sum <- max(apply(gravity_model,1,sum))
gravity_model <- gravity_model/max_row_sum

gravity_distance_model <- DistanceModel(list(gravity_model), 
                                      priorAlpha = 1,
                                      priorBeta = 10)





# figure out how to incorporate distance if considering analysis of several countries...
# https://github.com/grantbrown/ABSEIR/issues/1

# FIX SO THAT 1S PRESENT FOR BORDERS AND NOT WEIGHTED DISTANCE

```

```{r}

# Model to describe E to I and I to R transition probabilities.

# Latent period: 2-14 days with median 5

# find proper reference supporting this info  ^^

pickWeibullPars <- function(qdf){
  rslt <- optim(par = c(1,1), fn = function(par){
    sum((qweibull(p = qdf$q, shape = par[1], scale = par[2]) - qdf$x)^2)
  })
  rslt$par
}

pickGammaHyperPars <- function(mean, ESS){
  b <- ESS/(mean+1)     # ESS = effective sample size
  a <- ESS - b          # b = event occur rate and a = number of events occurred
  c(a,b)
}

latent_par_means <- pickWeibullPars(qdf=data.frame(q=c(0.025,0.5,0.975),
                                                   x=c(2,5,14)))
infectious_par_means <- pickWeibullPars(qdf = data.frame(q=c(0.025,0.5,0.975),
                                                         x = c(10,14,32)))

weibull_transition_priors <- WeibullTransitionPriors(latent_shape_prior_alpha = pickGammaHyperPars(latent_par_means[1], 1000)[1],
                                            latent_shape_prior_beta = pickGammaHyperPars(latent_par_means[1], 1000)[2],
                                            latent_scale_prior_alpha = pickGammaHyperPars(latent_par_means[2], 1000)[1],
                                            latent_scale_prior_beta = pickGammaHyperPars(latent_par_means[2], 1000)[2],
                                            infectious_shape_prior_alpha = pickGammaHyperPars(infectious_par_means[1], 100)[1], #less certain about infectious period...in other words we have a larger range in which one can be infectious when compared to small latent period range so we use a smaller ESS
                                            infectious_shape_prior_beta = pickGammaHyperPars(infectious_par_means[1], 100)[2],
                                            infectious_scale_prior_alpha = pickGammaHyperPars(infectious_par_means[2], 100)[1],
                                            infectious_scale_prior_beta = pickGammaHyperPars(infectious_par_means[2], 100)[2])
```

```{r}
exp_transition_priors = ExponentialTransitionPriors(p_ei = 1-exp(-1/5.68),
                                                      
                                                      #1-exp(-1.67), #0.81,
                                                    #average 5.68 day incubation period...(1/7)*5.68 approx 0.81 percent chance of 
                                                    #transitioning to infectious in a week
                                     p_ir= 1-exp(-1/10), # probability of culturing virus declines to 6% after day 10
                                     p_ei_ess = 100,
                                     p_ir_ess = 10)
```

```{r sampling control, echo=TRUE, eval=TRUE}

sampling_control = SamplingControl(seed = 123123, 
                                    n_cores = 8,
                                    algorithm="Beaumont2009",
                                   list(batch_size = 2000,
                                         init_batch_size = 1000000,
                                         epochs = 1e6,
                                         max_batches = 200,
                                         shrinkage = 0.85,
                                         multivariate_perturbation=FALSE,
                                         keep_compartments = TRUE
                                    )
 )
# algorithm="Beaumont2009" for SMC-ABC

```

```{r runtime and summary, echo=TRUE, eval=TRUE}

#consider showing difference of weibull transition priors vs exponential transition priors

runtime1a = system.time(result1a <- SpatialSEIRModel(data_model_1,
                                                    exposure_model_1,
                                                    reinfection_model,
                                                    distance_model,
                                                   #weibull_transition_priors,
                                                    exp_transition_priors,
                                                    initial_values,
                                                    sampling_control,
                                                    samples = 100,
                                                    verbose = 2)) #2970.5

runtime1b = system.time(result1b <- SpatialSEIRModel(data_model_1,
                                                    exposure_model_1,
                                                    reinfection_model,
                                                    CAR_model,
                                                   #weibull_transition_priors,
                                                    exp_transition_priors,
                                                    initial_values,
                                                    sampling_control,
                                                    samples = 100,
                                                    verbose = 2)) #3509.9

runtime1c = system.time(result1c <- SpatialSEIRModel(data_model_1,
                                                    exposure_model_1,
                                                    reinfection_model,
                                                    gravity_distance_model,
                                                    #weibull_transition_priors,
                                                    exp_transition_priors,
                                                    initial_values,
                                                    sampling_control,
                                                    samples = 100,
                                                    verbose = 2))

# Interpretation of Beta_SE coefficients: https://github.com/grantbrown/ABSEIR/issues/17

# works fine with 20 locations....crashes with full 48 states

```
```{r}
timeMatrix = rbind(runtime1a,runtime1b, runtime1c)
rownames(timeMatrix) = paste("model", 1:3)
print(timeMatrix[,1:3])
```

```{r}
summary(result1a)
# se_2 = fl...should be least negative implying highest mean epidemic intensity...refer to cases per 100k which is also highest of 3
```
```{r}
summary(result1b)
```

```{r}
summary(result1c)
```


```{r}
runtime_1a_sims = system.time(simulations1a <- epidemic.simulations(result1a, replicates = 50))
runtime_1b_sims = system.time(simulations1b <- epidemic.simulations(result1b, replicates = 50))
runtime_1c_sims = system.time(simulations1c <- epidemic.simulations(result1c, replicates = 50))


```


```{r}
plotPosteriorPredictive_firstwave <- function(simulations, nm){
  Is <- lapply(simulations$simulationResults, function(x){x$I_star})
  Is <- array(Reduce(c, Is), dim = c(nrow(Is[[1]]),
                                           ncol(Is[[2]]),
                                           length(Is)))
  
  Ism <- apply(Is, 1:2, mean)
  Islb <- apply(Is, 1:2, quantile, probs = c(0.025))
  Isub <- apply(Is, 1:2, quantile, probs = c(0.975))
  
  plotLocation <- function(x, model){
    plot(first_wave_confirmed_sub[,x], ylim = c(0, max(Isub[,x])), xlab = "Epidemic Day", ylab = "New Cases",
         main = paste(model, "\n location ", 
                      colnames(spatial_sub)[x], sep = ""))
    lines(Ism[,x], lty = 1, col = "blue")
    lines(Islb[,x], lty = 2, col = "blue")
    lines(Isub[,x], lty = 2, col = "blue")

    
    legend("topleft", legend = c("Mean", "95% CI", "Observed"), lty = c(1,2,0), 
         pch = c(NA,NA,1), col = c("blue", "blue", "black"), cex = 1)
  }
  
  for (i in 1:ncol(spatial_sub)){
    plotLocation(i, nm)
  }
}
```

```{r}
plotPosteriorPredictive_firstwave(result1a, "Model 1a: Posterior Distribution")
plotPosteriorPredictive_firstwave(simulations1a, "Model 1a: Posterior Predictive Distribution")
```
```{r}
plotPosteriorPredictive_firstwave(result1b, "Model 1b: Posterior Distribution")
plotPosteriorPredictive_firstwave(simulations1b, "Model 1b: Posterior Predictive Distribution")
```

```{r}
plotPosteriorPredictive_firstwave(result1c, "Model 1c: Posterior Distribution")
plotPosteriorPredictive_firstwave(simulations1c, "Model 1c: Posterior Predictive Distribution")
```
```{r}
comps <- compareModels(modelList = list(result1a, result1b, result1c), n_samples = 100)
```

```{r}
rownames(comps) <- colnames(comps) <- c("Distance", "CAR", "Gravity")
print(comps)
```


